# ğŸ§  Projeto de Machine Learning - PrediÃ§Ã£o de Renda (>50k ou â‰¤50k)

Este projeto foi desenvolvido como parte de um curso de InteligÃªncia Artificial, com o objetivo de criar um **modelo de Machine Learning** capaz de prever se uma pessoa ganha **mais** ou **menos** de 50k por ano, com base em dados demogrÃ¡ficos e profissionais.

---

## ğŸ¯ Objetivo
O foco principal foi **maximizar a mÃ©trica F1-Score**, garantindo um bom equilÃ­brio entre **precisÃ£o** (precision) e **sensibilidade** (recall).  
AlÃ©m disso, foram testadas diferentes arquiteturas baseadas em **Ã¡rvores de decisÃ£o** para avaliar desempenho e interpretabilidade.

---

## ğŸ“‚ Conjunto de Dados
O dataset foi dividido da seguinte forma:
- **Treino:** 70%
- **ValidaÃ§Ã£o:** 15%
- **Teste:** 15%

Cada arquivo contÃ©m **45.225 instÃ¢ncias** e **15 atributos** originais, totalizando **45 atributos** apÃ³s engenharia de variÃ¡veis.

---

## ğŸ› ï¸ Pipeline de Desenvolvimento

### ğŸ”¹ PrÃ©-processamento
- Tratamento de valores faltantes.
- Agrupamento de categorias raras.
- DetecÃ§Ã£o e tratamento de **outliers**.

### ğŸ”¹ Engenharia de Atributos
- **OrdinalEncoder** (`unknown_value=-1`) para variÃ¡veis categÃ³ricas â€” mais leve e adequado aos modelos baseados em Ã¡rvores.
- **StandardScaler** para variÃ¡veis numÃ©ricas.

### ğŸ”¹ Balanceamento de Classes
- AplicaÃ§Ã£o de **SMOTEENN** dentro do pipeline para lidar com desbalanceamento.

### ğŸ”¹ ValidaÃ§Ã£o
- **ValidaÃ§Ã£o cruzada estratificada (Stratified K-Fold)** para avaliar a robustez dos modelos e evitar overfitting.

### ğŸ”¹ OtimizaÃ§Ã£o de HiperparÃ¢metros
- **RandomizedSearchCV** para busca eficiente de combinaÃ§Ãµes.
- **Early stopping** para evitar overfitting.
- Salvamento dos melhores hiperparÃ¢metros em **JSON** para reaproveitamento.

### ğŸ”¹ Stacking & Out-of-Fold (OOF)
- CriaÃ§Ã£o de um **meta-modelo Logistic Regression** treinado sobre as probabilidades OOF geradas pelos modelos base.

### ğŸ”¹ CalibraÃ§Ã£o & Thresholding
- **CalibratedClassifierCV** para ajustar as probabilidades.
- OtimizaÃ§Ã£o do threshold com base na curva **precision-recall**.

### ğŸ”¹ Ensemble
- CombinaÃ§Ã£o ponderada das probabilidades dos 3 modelos para maximizar a F1.

### ğŸ”¹ Explainability (XAI)
- **SHAP** para interpretar a importÃ¢ncia e contribuiÃ§Ã£o de cada variÃ¡vel nas previsÃµes.

---

## ğŸ¤– Modelos Utilizados
Foram testados e comparados 3 algoritmos baseados em Ã¡rvores de decisÃ£o:

1. **XGBoost**
2. **LightGBM**
3. **CatBoost**

---

## ğŸ“Š Resultados

**Conjunto de Teste**

ğŸ”¹ **XGBoost**  
- F1-Score: `0.7180`  
- Recall: `0.7500`  
- Acertos: `4216` de `5642` (classe 0) | `1263` de `1684` (classe 1)  

ğŸ”¹ **LightGBM**  
- F1-Score: `0.7175`  
- Recall: `0.7488`  
- Acertos: `4214` de `5642` (classe 0) | `1262` de `1684` (classe 1)  

ğŸ”¹ **CatBoost**  
- F1-Score: `0.7159`  
- Recall: `0.7476`  
- Acertos: `4210` de `5642` (classe 0) | `1258` de `1684` (classe 1)  

ğŸ“Œ **AcurÃ¡cia geral**: ~87%  

---

## ğŸš€ PrÃ³ximos Passos
Ainda estou trabalhando neste projeto para:
- Explorar novos mÃ©todos de engenharia de atributos.
- Ajustar pesos do ensemble.
- Testar modelos hÃ­bridos.
- Melhorar a mÃ©trica **F1**.

---

## ğŸ“Œ Tecnologias e Bibliotecas
- **Python**  
- **Pandas, NumPy, Scikit-learn**  
- **XGBoost, LightGBM, CatBoost**  
- **SHAP**  
- **Imbalanced-learn**  

---
